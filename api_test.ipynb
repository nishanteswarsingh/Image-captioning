{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from pickle import dump, load\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_filename = 'tokenizer.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "      if index == integer:\n",
    "          return word\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# We need sudo prefix if not on a Google Colab.\n",
    "if 'google.colab' not in sys.modules:\n",
    "  SUDO_IF_NEEDED = 'sudo'\n",
    "else:\n",
    "  SUDO_IF_NEEDED = ''\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | {SUDO_IF_NEEDED} tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | {SUDO_IF_NEEDED} apt-key add -\n",
    "!{SUDO_IF_NEEDED} apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install tensorflow-model-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR=\"crnn_model_19\"\n",
    "MODEL_DIR_tw=\"xception\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=model_crnn \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8502 \\\n",
    "  --model_name=model_xception \\\n",
    "  --model_base_path=\"${MODEL_DIR_tw}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_api(filename):\n",
    "    try:\n",
    "        image = Image.open(filename)\n",
    "    except:\n",
    "        print(\"ERROR: Couldn't open image! Make sure the image path and extension is correct\")\n",
    "    image = image.resize((299,299))\n",
    "    image = np.array(image)\n",
    "    # for images that has 4 channels, we convert them into 3 channels\n",
    "    if image.shape[2] == 4: \n",
    "        image = image[..., :3]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image/127.5\n",
    "    image = image - 1.0\n",
    "    # print(image.shape,\" Shape of input to server\")\n",
    "    data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": image.tolist()})\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    json_response = requests.post('http://localhost:8504/v1/models/mdl:predict', data=data, headers=headers)\n",
    "    predictions = json.loads(json_response.text)\n",
    "    feature=np.array(predictions[\"predictions\"])\n",
    "    # print(\"Shape of response from server = \",feature.shape)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc_api(tokenizer, photo, max_length):\n",
    "    in_text = 'start'\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    # print(photo)\n",
    "    # print(\"input for photo is \",photo.shape,\" type of photo is \",type(photo))\n",
    "    for i in range(max_length):\n",
    "        print(f\"Requesting {i}th time \")\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        # print('\\n',len([photo,sequence]),\" Shape of input to lstm\\n\")\n",
    "        # print(\"Shape for sequence is \",sequence.shape,\" type of sequence  is \",type(sequence))\n",
    "        in1=photo.tolist()\n",
    "        in2=sequence.tolist()\n",
    "        data = json.dumps({\"signature_name\":\"serving_default\",\"inputs\": {'input_2':in1,'input_3':in2}})\n",
    "        json_response = requests.post('http://localhost:8501/v1/models/mdlr:predict', data=data, headers=headers)\n",
    "        predictions = json.loads(json_response.text)\n",
    "        # print(\"Predicitons are \",predictions)\n",
    "        res=predictions['outputs']\n",
    "        pred_mdl=np.array(res)\n",
    "        pred = np.argmax(pred_mdl)\n",
    "        # print(pred,\"THis is prediction\")\n",
    "        # pred = model.predict([photo,sequence], verbose=0)\n",
    "        # print('Type of preds is ',type(pred))\n",
    "        word = word_for_id(pred, tokenizer)\n",
    "        # print(\"Outputted word is \",word)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'end':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_img_api(img_path):\n",
    "  max_length = 32\n",
    "  photo=extract_features_api(img_path)\n",
    "  tokenizer = load(open(tokenizer_filename,\"rb\"))\n",
    "  # xception_model = Xception(include_top=False, pooling=\"avg\")\n",
    "  img = Image.open(img_path)\n",
    "  description = generate_desc_api(tokenizer, photo, max_length)\n",
    "  print(description)\n",
    "  plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_api('3637013_c675de7705.jpg')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
